---
layout: post
title: Exponential family
tags: SVI
description: When the probability distributions can be written in the form of exponential family, it will facilitate the derivations of the expectations of variational distributions.
date: 2019-07-26
---

<p> When I was delving into the classical <a href="http://www.columbia.edu/~jwp2128/Papers/HoffmanBleiWangPaisley2013.pdf" target="_blank">Stochastic Variational Inference</a>(SVI) paper, I found SVI is built upon natural gradients which are based on the form of exponential family. In particular, exponential family significantly facilitates the derivations of the expectations of variational distributions.</p>

Most of the distributions we have seen are from exponential family, except the Gaussian mixture. In this blog, I will summarize what I have explored and learned about exponential family. Also, I will present some beautiful properties from exponential family.

### Definition
The exponential family of distributions over $$x$$, given parameters $$\eta$$, is defined to be the set of distributions of the form

\begin{equation}
    p(x|\eta)=h(x) \exp \\{\eta^{T}T(x) -A(\eta)\\}
\end{equation}

where:

* $$\eta$$ is a vector of natural parameters
* $$T(x)$$ is sufficent statistics
* $$A(\eta)$$ is log normalizer

Let me explain the log normalizer a little bit more by calculating the integral of the above density estimation function over $$x$$
\begin{equation}
    \int p(x|\eta)dx=\frac{\int h(x) \exp \\{\eta^{T}T(x) \\}dx}{\exp\\{ A(\eta)\\} }=1
    \label{eq:integral}
\end{equation}
\begin{equation}
    A(\eta)=\log \left(\int h(x) \exp \\{\eta^{T}T(x) \\}dx\right)
    \label{eq:log-normalizer}
\end{equation}
From Eq. \eqref{eq:integral} and Eq. \eqref{eq:log-normalizer}, we can get why $$A(\eta)$$ is dubbed log normalizer.

### Beautiful properties

If we take the first derivative of the log normalizer, i.e. Eq. \eqref{eq:log-normalizer}, with respect to $\eta$, we have

$$
    \begin{aligned}
    \frac{\partial A(\eta)}{\partial \eta}
    &=\frac{\partial \log \left(\int h(x) \exp \{\eta^{T}T(x)\}dx\right) }{\partial \eta}\\
    &=\frac{\int h(x) \exp \{\eta^{T}T(x)\}T(x)dx }{\int h(x) \exp \{\eta^{T}T(x) \}dx}\\
    &\overset{\eqref{eq:integral}}{=}\frac{\int h(x)\exp\{\eta^{T}T(x)\}T(x)dx}{\exp\{A(\eta)\}}\\
    &=\int h(x)\exp\{\eta^{T}T(x)-A(\eta)\}T(x)dx
    \end{aligned}\tag{4}
$$

Let's see what happens if we take second derivative,

$$
    \begin{aligned} 
    \frac{\partial A(\eta)}{\partial \eta \partial \eta^{T}} &=\frac{\partial}{\partial \eta^{T}} \int h(x) \exp \left\{\eta^{T} T(x)-A(\eta)\right\} T(x) dx \\ 
    &=\int h(x) \exp \left\{\eta^{T} T(x)-A(\eta)\right\} T(x)\left(T(x)-A^{\prime}(\eta)\right) dx \\ 
    &=\int p(x | \eta) T^{2}(x) d x-A^{\prime}(\eta) \int p(x | \eta) T(x) d x \\ &=E\left[T^{2}(x)\right]-E[T(x)] E[T(x)] \\ 
    &=Var[T(x)]
    \end{aligned}
$$

Another property from exponential family is that the second derivative of log normalizer equals the variance of sufficient statistics.

Some examples

Let's look at some common probability distributions which can be written in the form of exponential family.

Gaussian distribution

$$
    \begin{aligned}
        p\left(x | \mu, \sigma^{2}\right) &=\frac{1}{\left(2 \pi \sigma^{2}\right)^{1 / 2}} \exp \left\{-\frac{1}{2 \sigma^{2}}(x-\mu)^{2}\right\} \\ &=\frac{1}{\left(2 \pi \sigma^{2}\right)^{1 / 2}} \exp \left\{-\frac{1}{2 \sigma^{2}} x^{2}+\frac{\mu}{\sigma^{2}} x-\frac{1}{2 \sigma^{2}} \mu^{2}\right\}
    \end{aligned}
$$
which, after some simple arrangement, can be cast in the standard exponential family form with
\begin{equation}
\eta=\left[\begin{array}{l}{\eta_{1}} \\ {\eta_{2}}\end{array}\right]=\left[\begin{array}{c}{\frac{\mu}{\sigma_{1}^{2}}} \\ {-\frac{1}{2 \sigma^{2}}}\end{array}\right]
\end{equation}

\begin{equation}
T(x)=\left(\begin{array}{l}{x} \\ {x^{2}}\end{array}\right)
\end{equation}

\begin{equation}
h(x)=(2 \pi)^{-1/2}
\end{equation}

\begin{equation}
A(\eta)=\frac{-\eta_{1}^{2}}{4 \eta_{2}}
\end{equation}

Dirichlet distribution

Suppose the parameters $\{\mu_k\}$ of multinomial distribution are drawn from a Dirichlet distribution parameterized by $\alpha$, we have


Links <br>
[LaTeX](https://en.wikipedia.org/wiki/LaTeX) <br>
[LaTeX installation guide](https://www.latex-tutorial.com/installation/) <br>
[Getting Started](http://www.maths.tcd.ie/~dwilkins/LaTeXPrimer/) <br>
